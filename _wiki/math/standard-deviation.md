---
layout  : wiki
title   : 표준편차의 공식이 두가지인 이유
summary : 표본분산과 차이, n-1로 나누는 이유 
date    : 2024-03-03 22:48:10 +0900
updated : 2024-03-03 22:48:10 +0900
tag     : 
toc     : true
public  : true
parent  : [[/math]] 
latex   : false
resource: 77F7BAE1-481C-47A8-A084-9D168C1BAE41
---
* TOC
{:toc}

분산과 표준편차는 데이터의 퍼짐 정도를 나타내는 중요한 통계적 수치입니다. 둘은 거의 같은 개념입니다. 단지 분산에 제곱근을 해 주어 값을 조정한 것이 표준편차입니다. A와 B 집단의 평균이 같다 해도 각 집단의 분산이나 표준편차의 차이에 따라 데이터의 형태는 완전히 다를 수 있습니다. 

예를 들어, 같은 평균을 가진 두 집단 A와 B가 있을 때, 집단 A의 데이터가 집단 B의 데이터보다 더 넓게 퍼져 있으면, A의 분산과 표준편차가 B보다 큽니다. 이 차이는 같은 평균 값을 가지더라도 두 집단의 데이터 분포가 얼마나 다를 수 있는지를 보여줍니다  

![sample-graph](https://github.com/JayFreemandev/JayFreemandev.github.io/assets/72185011/cc4e854a-5a22-46b7-bae7-5bd72ab9543e)

학급의 성적으로 이해를 해보면 A를 철수반, B를 민수반으로 볼때 철수네 반은 대부분 학생들의 성적이 서로 비슷하다.
1등이나 꼴등이나 큰 차이가 없고 고르게 컨닝 페이퍼를 돌린것처럼 평균 50점대의 성적을 가지고있다 반대로 민수반은
1등과 꼴등의 성적 차이가 매우 크다. 극상위권과 극하위권같이 학습 능력의 차이가 굉장히 크다고 볼 수 있다.

### 편차
편차는 각 데이터가 평균에서 얼마나 떨어져 있는지를 나타냅니다. 예를 들어, 친구 세 명이 시험을 봤고, 점수가 90점, 100점, 110점이라고 해봅시다. 평균 점수는 100점이죠. 각 친구의 점수에서 평균을 빼보면 -10, 0, +10이 되어, 모두 더하면 0이 됩니다. **이처럼 편차를 모두 더하면 항상 0이 됩니다.** 왜냐하면 어떤 값은 평균보다 높고, 어떤 값은 평균보다 낮기 때문이죠.

### 평균편차
평균편차는 **편차의 절댓값**(그냥 편차 더하면 0이 되버림)을 모두 더한 후, 데이터의 개수로 나눈 값입니다. 위 예시에서 편차의 절댓값은 10, 0, 10이므로, 평균편차는 (10+0+10)/3 = 20/3 ≈ 6.67입니다. 평균편차는 데이터가 평균에서 얼마나 떨어져 있는지를 평균적으로 나타냅니다. 하지만 계산하기 불편하다는 단점이 있어요.

### 분산
분산은 편차의 제곱을 모두 더한 후, 데이터의 개수로 나눈 값입니다. 편차는 음수도 존재하기 때문에 편차를 제곱하면 모든 값이 양수가 되므로, 데이터의 퍼짐 정도를 더 잘 나타낼 수 있습니다. 

### 표준편차
표준편차는 분산의 제곱근입니다. 데이터를 양수로 만들려고 제곱을 했기때문에 값이 실제보다 매우 멀어져있기 때문에 분산에 루트를 씌워서 다시 원래의 단위로 돌려놓아, 데이터의 퍼짐 정도를 더 직관적으로 이해할 수 있게 해줍니다.

### 모집단과 표본
모평균과 표본평균은 각각 모집단과 표본의 평균 값을 의미합니다. 표본분산은 표본 데이터의 분산을 나타내며, 모집단 분산의 추정치로 사용됩니다. 분산 계산 시 제곱을 사용하기 때문에, 모든 값은 양수가 됩니다. 이는 모평균과 표본평균 사이의 차이가 표본분산에 직접적인 영향을 주지 않음을 의미합니다.

여기서 어떨때는 n-1을 사용하고 어떨때는 n을 사용하는데 이것의 정체는 무엇인가?
모평균은 모든 정보가 공개되어있는 모집단에서의 평균을 나타낸다. 표본 평균은 아주 극히 공개된 정보를 가지고 값을 구하고 가려진 모르는 정보를 추정하겠다라고 할때 사용하는 개념이 표본 평균과 표본 분산이라는 개념이다. 

즉, 모든 정보를 가지고 모평균과 모분산을 구하는 방법과 제한된 정보를 가지고 값을 계산한 후 다시 전체 정보를 역으로 추정하는 계산 방식은 절대 같을 수가 없다는걸 다시 짚고 넘어가야한다.

### n-1과 자유도
```
가상의 표본 데이터 생성
sample_data = np.array([2, 4, 4, 4, 5, 5, 7, 9])

표본평균 계산
sample_mean = np.mean(sample_data)

표본분산 계산 (n-1로 나눔)
sample_variance = np.var(sample_data, ddof=1)

print(f"표본 데이터: {sample_data}")
print(f"표본평균: {sample_mean}")
print(f"표본분산: {sample_variance}")
```

np.var 함수의 ddof=1 옵션을 사용하여 표본분산을 계산할 때 n-1로 자유도를 고려한 보정을 적용한다. 모분산을 구할때는 n만 사용한다. 2,4,4,4,5,5,7,9의 표본 데이터를 계산했을때 8-1인 7로 나눈것것과 8로 나눈것중에 당연히 n-1로 더 작은수로 나눈것의 값이 훨씬 크다. 위에 정리했다싶이 애초에 표본 평균은 모평균과 같을 수 없다.

실제 모든 정보를 가지고 계산하는 값보다 작게 계산될 수 밖에 없는 것이다. 모집단에서 표본을 추출해 분산을 계산할 때, 우리는 모든 정보를 가지고 있지 않기 때문에, 실제 모집단의 분산(모분산)을 정확히 추정하기 어렵습니다. 잘못된 평균값을 가지고 잘못된 분산을 가지고 시작하는거다. 작게 나올 수 밖에 없기 때문에 값을 키워주기 위해 
n-1을 사용한다.

**다른 예시**  
1,2,3의 평균은 2 표준편차는 루트 3/2, 0.82다.   
이때 표본을 1,2로 잡으면 평균은 1.5, 모평균보다 작다.  
표본을 2,3으로 잡으면 평균은 2.5, 모평균보다 크다.  
운이 좋아 표본을 1,3으로 잡으면 평균이 2라 모평균과 같다.  

보면 크게 나올수도있다. 표본 평균으로 구한값이 모평균이랑 얼마나 비슷할까를 알기위해 신뢰 구간이라는 개념이 나온다.

분산의 경우는 다르다.
1,2 표본과 1.5의 간격은 0.5다. 0.5를 제곱한것의 평균은 0.25가 된다. 여기서 루트를 적용해 0.5  
2,3 표본은 0.5  
1,3 표본은 1  

모집단의 표준편차는 0.82가 나오는데 표본분산으로 구한 표준편차는 0.5, 0.5, 1의 평균인 0.67이 나온다.
즉 표본 표준편차로 모 표준편차를 추정하게되면 실제 모 표준편보다 과소 평가하게된다(높게 나올때도 있지만 낮게 나오는 빈도가 높음) 과소 추정이라고 부른다.

### 왜 과소 추정이 발생하는가?
분산이나 표준편차는 데이터가 얼마나 넓게 분포하고있는지를 알려준다. 그런 역할을 하는 지표가 최댓값과 최소값이다.
르브론 제임스처럼 2m가 있지만 148cm도 있다. 모집단에서 최대값과 최소값을 비교해보면 큰 차이가 난다는걸 알 수 있다. 하지만 랜덤하게 10명의 최대값과 최소값을 구하면 모집단의 차이보다는 작게나온다. 그럼 모집단보다는 과소평가 되었다 라고 말할 수 있다.

n이 아니라 n-1인 이유는 n−1은 이러한 '자유도'의 손실을 보정해줘서 모집단과 비슷하게 맞춰야하기 때문이다.

### 여론 조사
전체 인구 대상으로 여론을 조사할 수 없기 때문에 표본을 적당히 잡아서 조사하고 그게 모집단의 데이터와 얼추 비슷할것이라고 추정하는것이다. 

